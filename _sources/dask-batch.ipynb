{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pressing-guyana",
   "metadata": {},
   "source": [
    "# Batch Scripts\n",
    "\n",
    "When you're processing a large amount of data its a good idea to first test your analysis in an interactive job (e.g. using Jupyter) where you can refine your code quickly. Once you've got everything ready you can then move to a batch job and submit to the queue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-ebony",
   "metadata": {},
   "source": [
    "Batch jobs are submitted to the queue with a special program, Gadi uses `qsub`. The jobs are put into a queue alongside everyone else's jobs on the supercomputer, and the jobs get selected from the queue and run when there are free cpus on the supercomputer based on a number of priority factors - job size, walltime request, amount of time your project has used already etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-private",
   "metadata": {},
   "source": [
    "## Job Scripts\n",
    "\n",
    "A job script is a bash shell script. It lists the resources needed by the job, does any setup like loading modules, then runs your program:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#PBS -l ncpus=4\n",
    "#PBS -l mem=16gb\n",
    "#PBS -l walltime=1:00:00\n",
    "#PBS -l jobfs=100gb\n",
    "#PBS -l storage=gdata/hh5\n",
    "#PBS -l wd\n",
    "#PBS -j oe\n",
    "#PBS -W umask=0022\n",
    "\n",
    "module use /g/data/hh5/public/modules\n",
    "module load conda/analysis3\n",
    "\n",
    "python ./myscript.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-tennessee",
   "metadata": {},
   "source": [
    "You can run any type of program here, but you should make sure that there's some sort of parallelisation enabled in it if you request more than one CPU. This could be from a model using MPI, in which case you'd run it with `mpirun PROGRAM`, or a Python script using either Dask or `multiprocessing`.\n",
    "\n",
    ":::{note}\n",
    "The `#PBS` lines need to be at the start of the file, right after `#!/bin/bash`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-shield",
   "metadata": {},
   "source": [
    "## Dask Clients\n",
    "\n",
    "To enable Dask to use the resources requested by the run script you should start a Dask client. The simple way to do this on Gadi is to use `climtas.nci.GadiClient()`. Note that when you're using Dask (or `multiprocessing`) you need to put your entire script inside a `if __name__ == '__main__'` check:\n",
    "\n",
    "```python\n",
    "import climtas.nci\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    climtas.nci.GadiClient()\n",
    "    \n",
    "    # Rest of your script runs inside the 'if' check\n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-surveillance",
   "metadata": {},
   "source": [
    "The climtas function is a shortcut to starting a Dask client manually with the resources available to the queued job:\n",
    "\n",
    "```python\n",
    "import dask.distributed\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dask.distributed.Client(\n",
    "        n_workers = int(os.environ['PBS_NCPUS']),\n",
    "        memory_limit = int(os.environ['PBS_VMEM']) / int(os.environ['PBS_NCPUS']),\n",
    "        local_directory = os.path.join(os.environ['PBS_JOBFS'], 'dask-worker-space')\n",
    "    )\n",
    "    \n",
    "    # Rest of your script runs inside the 'if' check\n",
    "    # ...\n",
    "```\n",
    "\n",
    "It's important to set the memory limit, as the queue system will automatically kill your job if it uses more memory than it has requested. If you don't set the local directory then Dask will store temporary files in the current directory. For a large analysis these files can become quite large - putting them on the jobfs disk means they get cleaned up automatically when the job finishes.\n",
    "\n",
    ":::{note}\n",
    "This way of starting a Dask cluster only works on a single compute node, so if you're using Gadi's normal queue you can't use more than 48 CPUs. It's possible to set Dask up to use more than one node, but check how well your problem scales with increasing numbers of CPUs first.\n",
    ":::\n",
    "\n",
    ":::{note}\n",
    "If you're using the jobfs disk on Gadi, make sure your run script has a `#PBS -l jobfs` resource request\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-cherry",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Here's a small example batch setup. You submit the job with `qsub submit_mean.pbs`, the batch script then runs the python script for you.\n",
    "\n",
    "**submit_mean.pbs**\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#PBS -l ncpus=4\n",
    "#PBS -l mem=16gb\n",
    "#PBS -l walltime=1:00:00\n",
    "#PBS -l jobfs=100gb\n",
    "#PBS -l wd\n",
    "#PBS -l storage=gdata/hh5+gdata/rt52\n",
    "#PBS -W umask=0022\n",
    "#PBS -j oe\n",
    "\n",
    "module use /g/data3/hh5/public/modules\n",
    "module load conda/analysis3-21.04\n",
    "\n",
    "set -eu\n",
    "\n",
    "python ./mean.py\n",
    "```\n",
    "\n",
    "**mean\\.py**\n",
    "```python\n",
    "import xarray\n",
    "import climtas.nci\n",
    "\n",
    "# It's fine to define functions outside of the `if __name__ == '__main__'` statement\n",
    "def calc_mean(path, variable):\n",
    "    ds = xarray.open_mfdataset(path, combine='nested', concat_dim='time')\n",
    "    return ds[variable].mean()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    c = climtas.nci.GadiClient()\n",
    "    \n",
    "    path = \"/g/data/rt52/era5/single-levels/reanalysis/2t/2001/2t_era5_oper_sfc_*.nc\"\n",
    "    variable = 't2m'\n",
    "    \n",
    "    mean = calc_mean(path, variable)\n",
    "    print(mean.load())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-baseline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3] *",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
